{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"TpZufgx1veLO"},"outputs":[],"source":["from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3404,"status":"ok","timestamp":1704763626852,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"ZaWwPFttIVXg","outputId":"ef005d80-ac57-42a4-d30c-fcc904eeca91"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/.git/\n","remote: Enumerating objects: 311, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (26/26), done.\u001b[K\n","remote: Total 311 (delta 26), reused 15 (delta 15), pack-reused 270\u001b[K\n","Receiving objects: 100% (311/311), 31.17 MiB | 18.00 MiB/s, done.\n","Resolving deltas: 100% (118/118), done.\n","From https://github.com/RichardMinsooGo-ML/Bible_4_Part_F_10_Pytorch_Yolox2\n"," * branch            main       -> FETCH_HEAD\n"," * [new branch]      main       -> origin/main\n"]}],"source":["# Clone from Github Repository\n","! git init .\n","! git remote add origin https://github.com/RichardMinsooGo-ML/Bible_4_Part_F_10_Pytorch_Yolox2.git\n","# ! git pull origin master\n","! git pull origin main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YkFI6kZxtiAv"},"outputs":[],"source":["! pip install thop"]},{"cell_type":"code","source":["# Detect with Image\n","\n","# ! python demo.py --mode image \\\n","#                  --path_to_img /content/dataset/demo/images/ \\\n","#                  --cuda \\\n","#                  -m yolox2_s \\\n","#                  --weight /content/yolox2_s_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4 \\\n","#                  --show\n","\n","# See /content/det_results/demos/image"],"metadata":{"id":"5j-bB_5MhVvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect with Video\n","\n","# ! python demo.py --mode video \\\n","#                  --path_to_vid /content/dataset/demo/videos/street.mp4 \\\n","#                  --cuda \\\n","#                  -m yolox2_s \\\n","#                  --weight /content/yolox2_s_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4 \\\n","#                  --gif\n","                 # --show\n","# See /content/det_results/demos/video Download and check the results"],"metadata":{"id":"1hCPP79HhV1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect with Camera\n","# it don't work at Colab. Use laptop\n","\n","# ! python demo.py --mode camera \\\n","#                  --cuda \\\n","#                  -m yolox2_s \\\n","#                  --weight /content/yolox2_s_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4 \\\n","#                  --gif\n","                 # --show"],"metadata":{"id":"4mLA3urDh6Qw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jzffbi6Vu0eG"},"outputs":[],"source":["# COCO dataset download and extract\n","\n","# ! wget http://images.cocodataset.org/zips/train2017.zip\n","# ! wget http://images.cocodataset.org/zips/val2017.zip\n","# ! wget http://images.cocodataset.org/zips/test2017.zip\n","# ! wget http://images.cocodataset.org/zips/unlabeled2017.zip\n","\n","\n","# ! unzip train2017.zip  -d dataset/COCO\n","# ! unzip val2017.zip  -d dataset/COCO\n","# ! unzip test2017.zip  -d dataset/COCO\n","\n","# ! unzip unlabeled2017.zip -d dataset/COCO\n","\n","# ! rm train2017.zip\n","# ! rm val2017.zip\n","# ! rm test2017.zip\n","# ! rm unlabeled2017.zip\n","\n","# ! wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","# wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n","# wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n","# wget http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip\n","\n","# ! unzip annotations_trainval2017.zip -d dataset/COCO\n","# ! unzip stuff_annotations_trainval2017.zip\n","# ! unzip image_info_test2017.zip\n","# ! unzip image_info_unlabeled2017.zip\n","\n","# ! rm annotations_trainval2017.zip\n","# ! rm stuff_annotations_trainval2017.zip\n","# ! rm image_info_test2017.zip\n","# ! rm image_info_unlabeled2017.zip\n","\n","# clear_output()\n"]},{"cell_type":"code","source":["# Test YOLOx2\n","# ! python test.py --cuda \\\n","#                  -d coco \\\n","#                  --data_path /content/dataset \\\n","#                  -m yolox2_s \\\n","#                  --weight /content/yolox2_s_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4\n","                 # --show\n","# See /content/det_results/coco/yolox2"],"metadata":{"id":"fsdFSst4hVpA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate YOLOx2\n","# ! python eval.py --cuda \\\n","#                  -d coco-val \\\n","#                  --data_path /content/dataset \\\n","#                  --weight /content/yolox2_s_coco.pth \\\n","#                  -m yolox2_s"],"metadata":{"id":"5HdXMuMuhVsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VOC 2012 Dataset Download and extract\n","\n","! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n","!tar -xvf \"/content/VOCtrainval_11-May-2012.tar\" -C \"/content/dataset\"\n","clear_output()"],"metadata":{"id":"_osJSPjVcpra"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDvLejxcuGQH"},"outputs":[],"source":["# VOC 2007 Dataset Download and extract\n","\n","! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n","! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n","!tar -xvf \"/content/VOCtrainval_06-Nov-2007.tar\" -C \"/content/dataset\"\n","!tar -xvf \"/content/VOCtest_06-Nov-2007.tar\" -C \"/content/dataset\"\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3tewpR8SFkmI","executionInfo":{"status":"ok","timestamp":1704765271961,"user_tz":-540,"elapsed":1261667,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"656ea1cc-3d50-45df-88b4-ca443b147e4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=16, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolox2_n', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOX2_N ...\n","==============================\n","Transform: yolox_nano-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 10.0, 'translate': 0.1, 'scale': [0.5, 1.5], 'shear': 2.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': False, 'mosaic_prob': 1.0, 'mixup_prob': 0.5, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolox_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOX2_N ...\n","==============================\n","Model Configuration: \n"," {'bk_act': 'silu', 'bk_norm': 'BN', 'bk_depthwise': False, 'width': 0.25, 'depth': 0.34, 'ratio': 2.0, 'stride': [8, 16, 32], 'max_stride': 32, 'neck': 'sppf', 'neck_expand_ratio': 0.5, 'pooling_size': 5, 'neck_act': 'silu', 'neck_norm': 'BN', 'neck_depthwise': False, 'fpn': 'yolox2_pafpn', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'multi_scale': [0.7, 1.25], 'trans_type': 'yolox_nano', 'matcher': 'aligned_simota', 'matcher_hpy': {'soft_center_radius': 3.0, 'topk_candidates': 13}, 'loss_cls_weight': 1.0, 'loss_box_weight': 2.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Neck: sppf\n","==============================\n","FPN: Yolov8 PaFPN\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 7.83\n","Params : 2.74 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 0.5\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.00025\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Close < degress of rotation > ...\n"," - Close < shear of rotation >...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 1033/1034][lr: 0.000250][loss_cls: 1.10][loss_box: 0.65][loss_box_aux: 2.96][losses: 5.36][grad_norm: 11.82][time: 206.47][size: 640]\n","Train 2:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.87][loss_box: 0.53][loss_box_aux: 2.29][losses: 4.22][grad_norm: 8.64][time: 203.60][size: 544]\n","Train 3:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 1.02][loss_box: 0.41][loss_box_aux: 1.92][losses: 3.75][grad_norm: 7.67][time: 204.59][size: 544]\n","Train 4:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.87][loss_box: 0.44][loss_box_aux: 1.94][losses: 3.68][grad_norm: 6.52][time: 203.90][size: 576]\n","Train 5:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.78][loss_box: 0.39][loss_box_aux: 1.82][losses: 3.38][grad_norm: 7.67][time: 202.72][size: 672]\n","eval ...\n","im_detect: 500/4952 0.028s\n","im_detect: 1000/4952 0.026s\n","im_detect: 1500/4952 0.032s\n","im_detect: 2000/4952 0.028s\n","im_detect: 2500/4952 0.034s\n","im_detect: 3000/4952 0.028s\n","im_detect: 3500/4952 0.033s\n","im_detect: 4000/4952 0.029s\n","im_detect: 4500/4952 0.030s\n","im_detect: 4952/4952 0.030s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.3526\n","AP for bicycle = 0.2534\n","AP for bird = 0.0820\n","AP for boat = 0.1252\n","AP for bottle = 0.0990\n","AP for bus = 0.2852\n","AP for car = 0.4731\n","AP for cat = 0.2426\n","AP for chair = 0.1262\n","AP for cow = 0.2499\n","AP for diningtable = 0.2075\n","AP for dog = 0.2435\n","AP for horse = 0.2792\n","AP for motorbike = 0.3143\n","AP for person = 0.4526\n","AP for pottedplant = 0.0477\n","AP for sheep = 0.1849\n","AP for sofa = 0.1777\n","AP for train = 0.2388\n","AP for tvmonitor = 0.2671\n","Mean AP = 0.2351\n","Mean AP:  0.23511721632498928\n","Saving state, epoch: 5\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolox2_n \\\n","                  -bs 16 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale\n","#  yolox2_n, yolox2_t, yolox2_s, yolox2_m, yolox2_l, yolox2_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VpM9nVuZGEcP","executionInfo":{"status":"ok","timestamp":1704765276794,"user_tz":-540,"elapsed":4836,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"7dda8bf7-b0d6-414c-d27a-bc981ef01026"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=16, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolox2_t', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOX2_T ...\n","Traceback (most recent call last):\n","  File \"/content/train.py\", line 190, in <module>\n","    train()\n","  File \"/content/train.py\", line 134, in train\n","    model_cfg = build_model_config(args)\n","  File \"/content/config/__init__.py\", line 91, in build_model_config\n","    return cfg\n","UnboundLocalError: local variable 'cfg' referenced before assignment\n"]}],"source":["# cannot train yolox2_t\n","# ! python train.py --cuda \\\n","#                   -d voc \\\n","#                   --data_path /content/dataset \\\n","#                   -m yolox2_t \\\n","#                   -bs 16 \\\n","#                   --max_epoch 5 \\\n","#                   --wp_epoch 1 \\\n","#                   --eval_epoch 5 \\\n","#                   --fp16 \\\n","#                   --ema \\\n","#                   --multi_scale\n","#  yolox2_n, yolox2_t, yolox2_s, yolox2_m, yolox2_l, yolox2_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFuTmMORGEig","executionInfo":{"status":"ok","timestamp":1704767017884,"user_tz":-540,"elapsed":1741094,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"6fff0566-e417-4dd7-d28a-9a9057249f77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=16, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolox2_s', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOX2_S ...\n","==============================\n","Transform: yolox_small-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 10.0, 'translate': 0.1, 'scale': [0.1, 2.0], 'shear': 2.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': False, 'mosaic_prob': 1.0, 'mixup_prob': 1.0, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolox_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOX2_S ...\n","==============================\n","Model Configuration: \n"," {'bk_act': 'silu', 'bk_norm': 'BN', 'bk_depthwise': False, 'width': 0.5, 'depth': 0.34, 'ratio': 2.0, 'stride': [8, 16, 32], 'max_stride': 32, 'neck': 'sppf', 'neck_expand_ratio': 0.5, 'pooling_size': 5, 'neck_act': 'silu', 'neck_norm': 'BN', 'neck_depthwise': False, 'fpn': 'yolox2_pafpn', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'multi_scale': [0.7, 1.25], 'trans_type': 'yolox_small', 'matcher': 'aligned_simota', 'matcher_hpy': {'soft_center_radius': 3.0, 'topk_candidates': 13}, 'loss_cls_weight': 1.0, 'loss_box_weight': 2.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Neck: sppf\n","==============================\n","FPN: Yolov8 PaFPN\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 30.86\n","Params : 10.92 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 1.0\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.00025\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Close < degress of rotation > ...\n"," - Close < shear of rotation >...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 1033/1034][lr: 0.000250][loss_cls: 1.12][loss_box: 0.44][loss_box_aux: 2.31][losses: 4.31][grad_norm: 11.91][time: 301.32][size: 640]\n","Train 2:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.94][loss_box: 0.50][loss_box_aux: 2.18][losses: 4.12][grad_norm: 7.43][time: 298.47][size: 544]\n","Train 3:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.80][loss_box: 0.37][loss_box_aux: 1.68][losses: 3.22][grad_norm: 7.47][time: 298.93][size: 544]\n","Train 4:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.80][loss_box: 0.37][loss_box_aux: 1.75][losses: 3.28][grad_norm: 6.22][time: 298.68][size: 576]\n","Train 5:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.89][loss_box: 0.39][loss_box_aux: 1.75][losses: 3.42][grad_norm: 6.11][time: 294.77][size: 672]\n","eval ...\n","im_detect: 500/4952 0.030s\n","im_detect: 1000/4952 0.027s\n","im_detect: 1500/4952 0.030s\n","im_detect: 2000/4952 0.029s\n","im_detect: 2500/4952 0.031s\n","im_detect: 3000/4952 0.030s\n","im_detect: 3500/4952 0.036s\n","im_detect: 4000/4952 0.032s\n","im_detect: 4500/4952 0.032s\n","im_detect: 4952/4952 0.029s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.3875\n","AP for bicycle = 0.3410\n","AP for bird = 0.1199\n","AP for boat = 0.1396\n","AP for bottle = 0.1297\n","AP for bus = 0.3749\n","AP for car = 0.5496\n","AP for cat = 0.3348\n","AP for chair = 0.1880\n","AP for cow = 0.2281\n","AP for diningtable = 0.2686\n","AP for dog = 0.1975\n","AP for horse = 0.3497\n","AP for motorbike = 0.3625\n","AP for person = 0.5288\n","AP for pottedplant = 0.0769\n","AP for sheep = 0.2442\n","AP for sofa = 0.2015\n","AP for train = 0.3586\n","AP for tvmonitor = 0.2497\n","Mean AP = 0.2815\n","Mean AP:  0.281545437167241\n","Saving state, epoch: 5\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolox2_s \\\n","                  -bs 16 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale\n","#  yolox2_n, yolox2_t, yolox2_s, yolox2_m, yolox2_l, yolox2_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-HFOenHFZJjr","outputId":"ac7c0c19-2804-473c-d7d1-1c68510d5192","executionInfo":{"status":"ok","timestamp":1704770110172,"user_tz":-540,"elapsed":3092291,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=16, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolox2_m', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOX2_M ...\n","==============================\n","Transform: yolox_medium-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 10.0, 'translate': 0.1, 'scale': [0.1, 2.0], 'shear': 2.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': False, 'mosaic_prob': 1.0, 'mixup_prob': 1.0, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolox_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOX2_M ...\n","==============================\n","Model Configuration: \n"," {'bk_act': 'silu', 'bk_norm': 'BN', 'bk_depthwise': False, 'width': 0.75, 'depth': 0.67, 'ratio': 1.5, 'stride': [8, 16, 32], 'max_stride': 32, 'neck': 'sppf', 'neck_expand_ratio': 0.5, 'pooling_size': 5, 'neck_act': 'silu', 'neck_norm': 'BN', 'neck_depthwise': False, 'fpn': 'yolox2_pafpn', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'multi_scale': [0.7, 1.25], 'trans_type': 'yolox_medium', 'matcher': 'aligned_simota', 'matcher_hpy': {'soft_center_radius': 3.0, 'topk_candidates': 13}, 'loss_cls_weight': 1.0, 'loss_box_weight': 2.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Neck: sppf\n","==============================\n","FPN: Yolov8 PaFPN\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 86.44\n","Params : 26.30 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 1.0\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.00025\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Close < degress of rotation > ...\n"," - Close < shear of rotation >...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 1033/1034][lr: 0.000250][loss_cls: 1.16][loss_box: 0.48][loss_box_aux: 2.49][losses: 4.62][grad_norm: 9.38][time: 568.32][size: 640]\n","Train 2:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.95][loss_box: 0.36][loss_box_aux: 1.76][losses: 3.43][grad_norm: 9.77][time: 569.57][size: 544]\n","Train 3:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.94][loss_box: 0.46][loss_box_aux: 1.93][losses: 3.79][grad_norm: 5.98][time: 570.44][size: 544]\n","Train 4:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.77][loss_box: 0.44][loss_box_aux: 1.75][losses: 3.40][grad_norm: 6.97][time: 567.68][size: 576]\n","Train 5:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.98][loss_box: 0.35][loss_box_aux: 1.79][losses: 3.48][grad_norm: 5.66][time: 559.51][size: 672]\n","eval ...\n","im_detect: 500/4952 0.031s\n","im_detect: 1000/4952 0.030s\n","im_detect: 1500/4952 0.033s\n","im_detect: 2000/4952 0.031s\n","im_detect: 2500/4952 0.037s\n","im_detect: 3000/4952 0.032s\n","im_detect: 3500/4952 0.034s\n","im_detect: 4000/4952 0.035s\n","im_detect: 4500/4952 0.034s\n","im_detect: 4952/4952 0.032s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.3834\n","AP for bicycle = 0.3558\n","AP for bird = 0.1793\n","AP for boat = 0.1720\n","AP for bottle = 0.1219\n","AP for bus = 0.3736\n","AP for car = 0.5816\n","AP for cat = 0.3022\n","AP for chair = 0.1650\n","AP for cow = 0.3701\n","AP for diningtable = 0.2589\n","AP for dog = 0.2864\n","AP for horse = 0.3742\n","AP for motorbike = 0.3650\n","AP for person = 0.5669\n","AP for pottedplant = 0.0557\n","AP for sheep = 0.2278\n","AP for sofa = 0.3016\n","AP for train = 0.3449\n","AP for tvmonitor = 0.3260\n","Mean AP = 0.3056\n","Mean AP:  0.3056232400887552\n","Saving state, epoch: 5\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolox2_m \\\n","                  -bs 16 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ulJG4bboGFyk","executionInfo":{"status":"ok","timestamp":1704774714830,"user_tz":-540,"elapsed":4604663,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"00f7b5f0-18b7-4cb2-fe6c-dc4b5298b025"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=16, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolox2_l', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOX2_L ...\n","==============================\n","Transform: yolox_large-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 10.0, 'translate': 0.1, 'scale': [0.1, 2.0], 'shear': 2.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': False, 'mosaic_prob': 1.0, 'mixup_prob': 1.0, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolox_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOX2_L ...\n","==============================\n","Model Configuration: \n"," {'bk_act': 'silu', 'bk_norm': 'BN', 'bk_depthwise': False, 'width': 1.0, 'depth': 1.0, 'ratio': 1.0, 'stride': [8, 16, 32], 'max_stride': 32, 'neck': 'sppf', 'neck_expand_ratio': 0.5, 'pooling_size': 5, 'neck_act': 'silu', 'neck_norm': 'BN', 'neck_depthwise': False, 'fpn': 'yolox2_pafpn', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'multi_scale': [0.7, 1.25], 'trans_type': 'yolox_large', 'matcher': 'aligned_simota', 'matcher_hpy': {'soft_center_radius': 3.0, 'topk_candidates': 13}, 'loss_cls_weight': 1.0, 'loss_box_weight': 2.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Neck: sppf\n","==============================\n","FPN: Yolov8 PaFPN\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 180.60\n","Params : 45.48 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 1.0\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.00025\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Close < degress of rotation > ...\n"," - Close < shear of rotation >...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 1033/1034][lr: 0.000250][loss_cls: 1.04][loss_box: 0.49][loss_box_aux: 2.33][losses: 4.34][grad_norm: 7.76][time: 859.88][size: 640]\n","Train 2:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.94][loss_box: 0.48][loss_box_aux: 2.05][losses: 3.95][grad_norm: 8.41][time: 861.15][size: 544]\n","Train 3:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.95][loss_box: 0.45][loss_box_aux: 2.07][losses: 3.91][grad_norm: 7.28][time: 863.88][size: 544]\n","Train 4:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 1.00][loss_box: 0.37][loss_box_aux: 1.74][losses: 3.48][grad_norm: 5.70][time: 860.65][size: 576]\n","Train 5:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 1033/1034][lr: 0.000267][loss_cls: 0.91][loss_box: 0.35][loss_box_aux: 1.59][losses: 3.20][grad_norm: 5.32][time: 847.47][size: 672]\n","eval ...\n","im_detect: 500/4952 0.046s\n","im_detect: 1000/4952 0.039s\n","im_detect: 1500/4952 0.044s\n","im_detect: 2000/4952 0.041s\n","im_detect: 2500/4952 0.045s\n","im_detect: 3000/4952 0.044s\n","im_detect: 3500/4952 0.043s\n","im_detect: 4000/4952 0.043s\n","im_detect: 4500/4952 0.042s\n","im_detect: 4952/4952 0.039s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.3122\n","AP for bicycle = 0.3388\n","AP for bird = 0.1810\n","AP for boat = 0.1843\n","AP for bottle = 0.1119\n","AP for bus = 0.3634\n","AP for car = 0.5962\n","AP for cat = 0.3136\n","AP for chair = 0.1817\n","AP for cow = 0.3148\n","AP for diningtable = 0.2563\n","AP for dog = 0.2606\n","AP for horse = 0.3942\n","AP for motorbike = 0.3736\n","AP for person = 0.5695\n","AP for pottedplant = 0.0425\n","AP for sheep = 0.2493\n","AP for sofa = 0.2449\n","AP for train = 0.3190\n","AP for tvmonitor = 0.3039\n","Mean AP = 0.2956\n","Mean AP:  0.2955866188112816\n","Saving state, epoch: 5\n"]}],"source":["# T4 GPU 14.7G\n","\n","! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolox2_l \\\n","                  -bs 16 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale\n","#  yolox2_n, yolox2_t, yolox2_s, yolox2_m, yolox2_l, yolox2_x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VDYV4_nsGF5-","executionInfo":{"status":"ok","timestamp":1704783669840,"user_tz":-540,"elapsed":8888659,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"354c2d93-1e90-4e57-91a0-641ab166da2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=8, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolox2_x', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOX2_X ...\n","==============================\n","Transform: yolox_huge-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 10.0, 'translate': 0.1, 'scale': [0.1, 2.0], 'shear': 2.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': False, 'mosaic_prob': 1.0, 'mixup_prob': 1.0, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolox_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOX2_X ...\n","==============================\n","Model Configuration: \n"," {'bk_act': 'silu', 'bk_norm': 'BN', 'bk_depthwise': False, 'width': 1.25, 'depth': 1.34, 'ratio': 1.0, 'stride': [8, 16, 32], 'max_stride': 32, 'neck': 'sppf', 'neck_expand_ratio': 0.5, 'pooling_size': 5, 'neck_act': 'silu', 'neck_norm': 'BN', 'neck_depthwise': False, 'fpn': 'yolox2_pafpn', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'multi_scale': [0.7, 1.25], 'trans_type': 'yolox_huge', 'matcher': 'aligned_simota', 'matcher_hpy': {'soft_center_radius': 3.0, 'topk_candidates': 13}, 'loss_cls_weight': 1.0, 'loss_box_weight': 2.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Neck: sppf\n","==============================\n","FPN: Yolov8 PaFPN\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 337.68\n","Params : 85.00 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 1.0\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.000125\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Close < degress of rotation > ...\n"," - Close < shear of rotation >...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 2067/2068][lr: 0.000125][loss_cls: 1.01][loss_box: 0.42][loss_box_aux: 2.08][losses: 3.93][grad_norm: 11.51][time: 1686.19][size: 544]\n","Train 2:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 2067/2068][lr: 0.000133][loss_cls: 1.05][loss_box: 0.36][loss_box_aux: 1.85][losses: 3.61][grad_norm: 8.28][time: 1687.17][size: 576]\n","Train 3:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 2067/2068][lr: 0.000133][loss_cls: 0.85][loss_box: 0.42][loss_box_aux: 2.20][losses: 3.88][grad_norm: 10.10][time: 1694.09][size: 576]\n","Train 4:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 2067/2068][lr: 0.000133][loss_cls: 0.85][loss_box: 0.35][loss_box_aux: 1.43][losses: 2.98][grad_norm: 11.09][time: 1699.00][size: 544]\n","Train 5:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 2067/2068][lr: 0.000133][loss_cls: 0.74][loss_box: 0.35][loss_box_aux: 1.69][losses: 3.13][grad_norm: 7.56][time: 1692.25][size: 640]\n","eval ...\n","im_detect: 500/4952 0.069s\n","im_detect: 1000/4952 0.066s\n","im_detect: 1500/4952 0.066s\n","im_detect: 2000/4952 0.065s\n","im_detect: 2500/4952 0.069s\n","im_detect: 3000/4952 0.066s\n","im_detect: 3500/4952 0.068s\n","im_detect: 4000/4952 0.068s\n","im_detect: 4500/4952 0.066s\n","im_detect: 4952/4952 0.067s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.4219\n","AP for bicycle = 0.3391\n","AP for bird = 0.1951\n","AP for boat = 0.2014\n","AP for bottle = 0.1429\n","AP for bus = 0.4475\n","AP for car = 0.6241\n","AP for cat = 0.3471\n","AP for chair = 0.2022\n","AP for cow = 0.3502\n","AP for diningtable = 0.3260\n","AP for dog = 0.2606\n","AP for horse = 0.3976\n","AP for motorbike = 0.3963\n","AP for person = 0.6272\n","AP for pottedplant = 0.1025\n","AP for sheep = 0.2295\n","AP for sofa = 0.3453\n","AP for train = 0.3538\n","AP for tvmonitor = 0.3544\n","Mean AP = 0.3332\n","Mean AP:  0.33322950249315375\n","Saving state, epoch: 5\n"]}],"source":["# T4 GPU 14.0 G\n","\n","! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolox2_x \\\n","                  -bs 8 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale\n","#  yolox2_n, yolox2_t, yolox2_s, yolox2_m, yolox2_l, yolox2_x"]},{"cell_type":"code","source":["# Cannot test at Colab-Pro + environment\n","\n","# ! python -m torch.distributed.run --nproc_per_node=8 train.py \\\n","#                                   --cuda \\\n","#                                   -dist \\\n","#                                   -d voc \\\n","#                                   --data_path /content/dataset \\\n","#                                   -m yolox2_s \\\n","#                                   -bs 128 \\\n","#                                   -size 640 \\\n","#                                   --wp_epoch 3 \\\n","#                                   --max_epoch 300 \\\n","#                                   --eval_epoch 10 \\\n","#                                   --no_aug_epoch 20 \\\n","#                                   --ema \\\n","#                                   --fp16 \\\n","#                                   --sybn \\\n","#                                   --multi_scale \\\n","#                                   --save_folder weights/\n","\n"],"metadata":{"id":"KS2VWvIbAj6H"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyN/KvZs8JIkJbQu/whpTIHf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}