{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"TpZufgx1veLO","executionInfo":{"status":"ok","timestamp":1704147486947,"user_tz":-540,"elapsed":6,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"outputs":[],"source":["from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3890,"status":"ok","timestamp":1704147490832,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"ZaWwPFttIVXg","outputId":"d7830d26-6d04-413c-bceb-eb0e5b3ec378"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/.git/\n","remote: Enumerating objects: 308, done.\u001b[K\n","remote: Counting objects: 100% (46/46), done.\u001b[K\n","remote: Compressing objects: 100% (46/46), done.\u001b[K\n","remote: Total 308 (delta 25), reused 0 (delta 0), pack-reused 262\u001b[K\n","Receiving objects: 100% (308/308), 31.16 MiB | 15.43 MiB/s, done.\n","Resolving deltas: 100% (118/118), done.\n","From https://github.com/RichardMinsooGo-ML/Bible_4_Part_F_05_Pytorch_Yolov5\n"," * branch            main       -> FETCH_HEAD\n"," * [new branch]      main       -> origin/main\n"]}],"source":["# Clone from Github Repository\n","! git init .\n","! git remote add origin https://github.com/RichardMinsooGo-ML/Bible_4_Part_F_05_Pytorch_Yolov5.git\n","# ! git pull origin master\n","! git pull origin main"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6350,"status":"ok","timestamp":1704147497179,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"YkFI6kZxtiAv","outputId":"02bf4f1d-12aa-44b5-d9bc-6cb5a8fd6c64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n"]}],"source":["! pip install thop"]},{"cell_type":"code","source":["# yolov5 pretrained weight is not working at Colab\n","\n","# ! wget https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_n_coco.pth\n","# ! wget https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_s_coco.pth\n","# ! wget https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_m_coco.pth\n","# ! wget https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_l_coco.pth"],"metadata":{"id":"LAYjU_A7eMrJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704147552035,"user_tz":-540,"elapsed":54859,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"da4bc2bf-e37e-467c-ba87-1c0278bd4180"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-01 22:18:16--  https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_n_coco.pth\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/1a6e53cc-21b4-4855-b637-56c82ab9e332?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221817Z&X-Amz-Expires=300&X-Amz-Signature=16408aff14c619d5222f8b29719bfac874ccda0712bfd134e2f5ff42d871dbd4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_n_coco.pth&response-content-type=application%2Foctet-stream [following]\n","--2024-01-01 22:18:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/1a6e53cc-21b4-4855-b637-56c82ab9e332?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221817Z&X-Amz-Expires=300&X-Amz-Signature=16408aff14c619d5222f8b29719bfac874ccda0712bfd134e2f5ff42d871dbd4&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_n_coco.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19427717 (19M) [application/octet-stream]\n","Saving to: ‘yolov5_n_coco.pth’\n","\n","yolov5_n_coco.pth   100%[===================>]  18.53M  8.52MB/s    in 2.2s    \n","\n","2024-01-01 22:18:20 (8.52 MB/s) - ‘yolov5_n_coco.pth’ saved [19427717/19427717]\n","\n","--2024-01-01 22:18:20--  https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_s_coco.pth\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/4dbef7f7-728b-4a7d-b489-b1e6abe8565e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221821Z&X-Amz-Expires=300&X-Amz-Signature=523928bb72f60be912fcc1f7f873d1b37eeffb650d02939b3bd77cae4f4ce556&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_s_coco.pth&response-content-type=application%2Foctet-stream [following]\n","--2024-01-01 22:18:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/4dbef7f7-728b-4a7d-b489-b1e6abe8565e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221821Z&X-Amz-Expires=300&X-Amz-Signature=523928bb72f60be912fcc1f7f873d1b37eeffb650d02939b3bd77cae4f4ce556&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_s_coco.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 72611717 (69M) [application/octet-stream]\n","Saving to: ‘yolov5_s_coco.pth’\n","\n","yolov5_s_coco.pth   100%[===================>]  69.25M  16.5MB/s    in 5.2s    \n","\n","2024-01-01 22:18:27 (13.3 MB/s) - ‘yolov5_s_coco.pth’ saved [72611717/72611717]\n","\n","--2024-01-01 22:18:27--  https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_m_coco.pth\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/c3f4ace8-a5e5-4335-b940-988335be743c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221828Z&X-Amz-Expires=300&X-Amz-Signature=8c33cc38f9ddfbd6336ea826b608ee9065ef3482966e65eac1e2350997a99849&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_m_coco.pth&response-content-type=application%2Foctet-stream [following]\n","--2024-01-01 22:18:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/c3f4ace8-a5e5-4335-b940-988335be743c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221828Z&X-Amz-Expires=300&X-Amz-Signature=8c33cc38f9ddfbd6336ea826b608ee9065ef3482966e65eac1e2350997a99849&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_m_coco.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 203896277 (194M) [application/octet-stream]\n","Saving to: ‘yolov5_m_coco.pth’\n","\n","yolov5_m_coco.pth   100%[===================>] 194.45M  17.4MB/s    in 11s     \n","\n","2024-01-01 22:18:40 (17.3 MB/s) - ‘yolov5_m_coco.pth’ saved [203896277/203896277]\n","\n","--2024-01-01 22:18:41--  https://github.com/yjh0410/RT-ODLab/releases/download/yolo_tutorial_ckpt/yolov5_l_coco.pth\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/127981c0-8227-43fd-9bf6-09253c5e28fb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221841Z&X-Amz-Expires=300&X-Amz-Signature=e8726b838dff135628b95802473a7235bf98c2b912c20f4a98f8d0340f67b061&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_l_coco.pth&response-content-type=application%2Foctet-stream [following]\n","--2024-01-01 22:18:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/617790085/127981c0-8227-43fd-9bf6-09253c5e28fb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240101T221841Z&X-Amz-Expires=300&X-Amz-Signature=e8726b838dff135628b95802473a7235bf98c2b912c20f4a98f8d0340f67b061&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=617790085&response-content-disposition=attachment%3B%20filename%3Dyolov5_l_coco.pth&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 435398635 (415M) [application/octet-stream]\n","Saving to: ‘yolov5_l_coco.pth’\n","\n","yolov5_l_coco.pth   100%[===================>] 415.23M  15.0MB/s    in 29s     \n","\n","2024-01-01 22:19:10 (14.6 MB/s) - ‘yolov5_l_coco.pth’ saved [435398635/435398635]\n","\n"]}]},{"cell_type":"code","source":["# Detect with Image\n","\n","# ! python demo.py --mode image \\\n","#                  --path_to_img /content/dataset/demo/images/ \\\n","#                  --cuda \\\n","#                  -m yolov5_l \\\n","#                  --weight /content/yolov5_l_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4\n","                 # --show\n","\n","# See /content/det_results/demos/image"],"metadata":{"id":"5j-bB_5MhVvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect with Video\n","\n","# ! python demo.py --mode video \\\n","#                  --path_to_vid /content/dataset/demo/videos/street.mp4 \\\n","#                  --cuda -m yolov5_m \\\n","#                  --weight /content/yolov5_m_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4 \\\n","#                  --gif\n","                 # --show\n","\n","# See /content/det_results/demos/video Download and check the results"],"metadata":{"id":"1hCPP79HhV1A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Detect with Camera\n","# it don't work at Colab. Use laptop\n","\n","# ! python demo.py --mode camera \\\n","#                  --cuda \\\n","#                  -m yolov5_s \\\n","#                  --weight /content/yolov5_s_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4 \\\n","#                  --gif\n","                 # --show\n"],"metadata":{"id":"4mLA3urDh6Qw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Jzffbi6Vu0eG","executionInfo":{"status":"ok","timestamp":1704148188293,"user_tz":-540,"elapsed":621895,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"outputs":[],"source":["# COCO dataset download and extract\n","\n","# ! wget http://images.cocodataset.org/zips/train2017.zip\n","! wget http://images.cocodataset.org/zips/val2017.zip\n","! wget http://images.cocodataset.org/zips/test2017.zip\n","# ! wget http://images.cocodataset.org/zips/unlabeled2017.zip\n","\n","\n","# ! unzip train2017.zip  -d dataset/COCO\n","! unzip val2017.zip  -d dataset/COCO\n","! unzip test2017.zip  -d dataset/COCO\n","\n","# ! unzip unlabeled2017.zip -d dataset/COCO\n","\n","# ! rm train2017.zip\n","# ! rm val2017.zip\n","# ! rm test2017.zip\n","# ! rm unlabeled2017.zip\n","\n","! wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","# wget http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip\n","# wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n","# wget http://images.cocodataset.org/annotations/image_info_unlabeled2017.zip\n","\n","! unzip annotations_trainval2017.zip -d dataset/COCO\n","# ! unzip stuff_annotations_trainval2017.zip\n","# ! unzip image_info_test2017.zip\n","# ! unzip image_info_unlabeled2017.zip\n","\n","# ! rm annotations_trainval2017.zip\n","# ! rm stuff_annotations_trainval2017.zip\n","# ! rm image_info_test2017.zip\n","# ! rm image_info_unlabeled2017.zip\n","\n","clear_output()\n"]},{"cell_type":"code","source":["# Test YOLOv5\n","\n","# ! python test.py --cuda \\\n","#                  -d coco \\\n","#                  --data_path /content/dataset  \\\n","#                  -m yolov5_m \\\n","#                  --weight /content/yolov5_m_coco.pth \\\n","#                  -size 640 \\\n","#                  -vt 0.4\n","                 # --show\n","# See /content/det_results/coco/yolov5"],"metadata":{"id":"fsdFSst4hVpA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate YOLOv5\n","\n","# ! python eval.py --cuda \\\n","#                  -d coco-val \\\n","#                  --data_path /content/dataset \\\n","#                  --weight /content/yolov5_m_coco.pth \\\n","#                  -m yolov5_m\n"],"metadata":{"id":"5HdXMuMuhVsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# VOC 2012 Dataset Download and extract\n","\n","! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n","!tar -xvf \"/content/VOCtrainval_11-May-2012.tar\" -C \"/content/dataset\"\n","clear_output()"],"metadata":{"id":"_osJSPjVcpra","executionInfo":{"status":"ok","timestamp":1704148326657,"user_tz":-540,"elapsed":127871,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"GDvLejxcuGQH","executionInfo":{"status":"ok","timestamp":1704148387572,"user_tz":-540,"elapsed":60918,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}}},"outputs":[],"source":["# VOC 2007 Dataset Download and extract\n","\n","! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n","! wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar\n","!tar -xvf \"/content/VOCtrainval_06-Nov-2007.tar\" -C \"/content/dataset\"\n","!tar -xvf \"/content/VOCtest_06-Nov-2007.tar\" -C \"/content/dataset\"\n","clear_output()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1019210,"status":"ok","timestamp":1704149406779,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"outputId":"4b2417c0-c317-42c5-d5e2-4b08c7b56095","id":"hx4wva6_77ga"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=32, max_epoch=3, wp_epoch=1, eval_epoch=3, no_aug_epoch=20, model='yolov5_n', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOV5_N ...\n","==============================\n","Transform: yolov5_nano-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 0.0, 'translate': 0.1, 'scale': [0.5, 1.5], 'shear': 0.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': True, 'mosaic_prob': 1.0, 'mixup_prob': 0.0, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolov5_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOV5_N ...\n","==============================\n","Model Configuration: \n"," {'backbone': 'cspdarknet', 'bk_act': 'silu', 'bk_norm': 'BN', 'bk_dpw': False, 'width': 0.25, 'depth': 0.34, 'stride': [8, 16, 32], 'max_stride': 32, 'fpn': 'yolov5_pafpn', 'fpn_reduce_layer': 'Conv', 'fpn_downsample_layer': 'Conv', 'fpn_core_block': 'CSPBlock', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'anchor_size': [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]], 'multi_scale': [0.5, 1.25], 'trans_type': 'yolov5_nano', 'anchor_thresh': 4.0, 'loss_obj_weight': 1.0, 'loss_cls_weight': 1.0, 'loss_box_weight': 5.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 5.06\n","Params : 1.66 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.0005\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/517 [00:00<?, ?it/s]\n","[Epoch: 1/3][Iter: 516/517][lr: 0.000499][loss_obj: 5.66][loss_cls: 2.11][loss_box: 0.52][losses: 10.37][grad_norm: 7.60][time: 218.59][size: 672]\n","Train 2:   0%|          | 0/517 [00:00<?, ?it/s]\n","[Epoch: 2/3][Iter: 516/517][lr: 0.000529][loss_obj: 4.25][loss_cls: 2.06][loss_box: 0.45][losses: 8.53][grad_norm: 5.61][time: 220.07][size: 416]\n","Train 3:   0%|          | 0/517 [00:00<?, ?it/s]\n","[Epoch: 3/3][Iter: 516/517][lr: 0.000529][loss_obj: 4.29][loss_cls: 1.90][loss_box: 0.43][losses: 8.35][grad_norm: 5.75][time: 221.88][size: 512]\n","eval ...\n","im_detect: 1/4952 0.498s\n","im_detect: 501/4952 0.049s\n","im_detect: 1001/4952 0.049s\n","im_detect: 1501/4952 0.044s\n","im_detect: 2001/4952 0.045s\n","im_detect: 2501/4952 0.047s\n","im_detect: 3001/4952 0.046s\n","im_detect: 3501/4952 0.041s\n","im_detect: 4001/4952 0.047s\n","im_detect: 4501/4952 0.055s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.0865\n","AP for bicycle = 0.1269\n","AP for bird = 0.0364\n","AP for boat = 0.0939\n","AP for bottle = 0.0009\n","AP for bus = 0.0242\n","AP for car = 0.1540\n","AP for cat = 0.0795\n","AP for chair = 0.0385\n","AP for cow = 0.1422\n","AP for diningtable = 0.0370\n","AP for dog = 0.0501\n","AP for horse = 0.1447\n","AP for motorbike = 0.1513\n","AP for person = 0.2101\n","AP for pottedplant = 0.0061\n","AP for sheep = 0.1171\n","AP for sofa = 0.0178\n","AP for train = 0.0234\n","AP for tvmonitor = 0.1408\n","Mean AP = 0.0841\n","Mean AP:  0.08406574451168303\n","Saving state, epoch: 3\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolov5_n \\\n","                  -bs 32 \\\n","                  --max_epoch 20 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 10 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0R6_OXZW8JR-","executionInfo":{"status":"ok","timestamp":1704149653851,"user_tz":-540,"elapsed":5397,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"84f4f0ba-8c82-4c11-b90d-ac6a627a3709"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=32, max_epoch=3, wp_epoch=1, eval_epoch=3, no_aug_epoch=20, model='yolov5_t', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOV5_T ...\n","Traceback (most recent call last):\n","  File \"/content/train.py\", line 190, in <module>\n","    train()\n","  File \"/content/train.py\", line 134, in train\n","    model_cfg = build_model_config(args)\n","  File \"/content/config/__init__.py\", line 92, in build_model_config\n","    return cfg\n","UnboundLocalError: local variable 'cfg' referenced before assignment\n"]}],"source":["# yolov5_t have some bug\n","# ! python train.py --cuda \\\n","#                   -d voc \\\n","#                   --data_path /content/dataset \\\n","#                   -m yolov5_t \\\n","#                   -bs 32 \\\n","#                   --max_epoch 3 \\\n","#                   --wp_epoch 1 \\\n","#                   --eval_epoch 3 \\\n","#                   --fp16 \\\n","#                   --ema \\\n","#                   --multi_scale"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nlm-y1V4784p","executionInfo":{"status":"ok","timestamp":1704150824370,"user_tz":-540,"elapsed":1170522,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"4d6700b1-570f-4ec5-fbc2-4c681dbc083e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=32, max_epoch=3, wp_epoch=1, eval_epoch=3, no_aug_epoch=20, model='yolov5_s', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOV5_S ...\n","==============================\n","Transform: yolov5_small-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 0.0, 'translate': 0.2, 'scale': [0.1, 2.0], 'shear': 0.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': True, 'mosaic_prob': 1.0, 'mixup_prob': 0.0, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolov5_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOV5_S ...\n","==============================\n","Model Configuration: \n"," {'backbone': 'cspdarknet', 'bk_act': 'silu', 'bk_norm': 'BN', 'bk_dpw': False, 'width': 0.5, 'depth': 0.34, 'stride': [8, 16, 32], 'max_stride': 32, 'fpn': 'yolov5_pafpn', 'fpn_reduce_layer': 'Conv', 'fpn_downsample_layer': 'Conv', 'fpn_core_block': 'CSPBlock', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'anchor_size': [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]], 'multi_scale': [0.5, 1.25], 'trans_type': 'yolov5_small', 'anchor_thresh': 4.0, 'loss_obj_weight': 1.0, 'loss_cls_weight': 1.0, 'loss_box_weight': 5.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 19.64\n","Params : 6.56 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.0005\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/517 [00:00<?, ?it/s]\n","[Epoch: 1/3][Iter: 516/517][lr: 0.000499][loss_obj: 5.43][loss_cls: 1.74][loss_box: 0.54][losses: 9.89][grad_norm: 6.93][time: 271.12][size: 672]\n","Train 2:   0%|          | 0/517 [00:00<?, ?it/s]\n","[Epoch: 2/3][Iter: 516/517][lr: 0.000529][loss_obj: 4.01][loss_cls: 1.70][loss_box: 0.49][losses: 8.18][grad_norm: 5.12][time: 273.15][size: 416]\n","Train 3:   0%|          | 0/517 [00:00<?, ?it/s]\n","[Epoch: 3/3][Iter: 516/517][lr: 0.000529][loss_obj: 4.62][loss_cls: 1.66][loss_box: 0.48][losses: 8.68][grad_norm: 6.43][time: 271.09][size: 512]\n","eval ...\n","im_detect: 500/4952 0.045s\n","im_detect: 1000/4952 0.044s\n","im_detect: 1500/4952 0.044s\n","im_detect: 2000/4952 0.047s\n","im_detect: 2500/4952 0.054s\n","im_detect: 3000/4952 0.048s\n","im_detect: 3500/4952 0.053s\n","im_detect: 4000/4952 0.045s\n","im_detect: 4500/4952 0.049s\n","im_detect: 4952/4952 0.049s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.1991\n","AP for bicycle = 0.0703\n","AP for bird = 0.0261\n","AP for boat = 0.0157\n","AP for bottle = 0.0049\n","AP for bus = 0.1440\n","AP for car = 0.2408\n","AP for cat = 0.1498\n","AP for chair = 0.1154\n","AP for cow = 0.1078\n","AP for diningtable = 0.0476\n","AP for dog = 0.1192\n","AP for horse = 0.1195\n","AP for motorbike = 0.1910\n","AP for person = 0.2135\n","AP for pottedplant = 0.0198\n","AP for sheep = 0.1375\n","AP for sofa = 0.0574\n","AP for train = 0.0620\n","AP for tvmonitor = 0.1598\n","Mean AP = 0.1101\n","Mean AP:  0.11005094586660011\n","Saving state, epoch: 3\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolov5_s \\\n","                  -bs 32 \\\n","                  --max_epoch 20 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 10 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2722807,"status":"ok","timestamp":1704153615140,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"},"user_tz":-540},"id":"2DBRcEdV_cus","outputId":"6470448e-747e-4ac5-e2db-0e553988b576"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=16, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolov5_m', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOV5_M ...\n","==============================\n","Transform: yolov5_medium-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 0.0, 'translate': 0.2, 'scale': [0.1, 2.0], 'shear': 0.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': True, 'mosaic_prob': 1.0, 'mixup_prob': 0.1, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolov5_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOV5_M ...\n","==============================\n","Model Configuration: \n"," {'backbone': 'cspdarknet', 'bk_act': 'silu', 'bk_norm': 'BN', 'bk_dpw': False, 'width': 0.75, 'depth': 0.67, 'stride': [8, 16, 32], 'max_stride': 32, 'fpn': 'yolov5_pafpn', 'fpn_reduce_layer': 'Conv', 'fpn_downsample_layer': 'Conv', 'fpn_core_block': 'CSPBlock', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'anchor_size': [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]], 'multi_scale': [0.5, 1.25], 'trans_type': 'yolov5_medium', 'anchor_thresh': 4.0, 'loss_obj_weight': 1.0, 'loss_cls_weight': 1.0, 'loss_box_weight': 5.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 50.56\n","Params : 17.61 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 0.1\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.00025\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 1033/1034][lr: 0.000250][loss_obj: 3.89][loss_cls: 1.84][loss_box: 0.46][losses: 8.05][grad_norm: 7.94][time: 470.86][size: 416]\n","Train 2:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 1033/1034][lr: 0.000267][loss_obj: 4.99][loss_cls: 1.74][loss_box: 0.43][losses: 8.90][grad_norm: 9.49][time: 473.05][size: 640]\n","Train 3:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 1033/1034][lr: 0.000267][loss_obj: 3.83][loss_cls: 1.67][loss_box: 0.43][losses: 7.66][grad_norm: 7.25][time: 461.94][size: 768]\n","Train 4:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 1033/1034][lr: 0.000267][loss_obj: 3.39][loss_cls: 1.96][loss_box: 0.42][losses: 7.43][grad_norm: 5.82][time: 465.27][size: 352]\n","Train 5:   0%|          | 0/1034 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 1033/1034][lr: 0.000267][loss_obj: 3.89][loss_cls: 1.21][loss_box: 0.34][losses: 6.78][grad_norm: 7.17][time: 470.24][size: 800]\n","eval ...\n","im_detect: 500/4952 0.049s\n","im_detect: 1000/4952 0.050s\n","im_detect: 1500/4952 0.056s\n","im_detect: 2000/4952 0.059s\n","im_detect: 2500/4952 0.063s\n","im_detect: 3000/4952 0.055s\n","im_detect: 3500/4952 0.059s\n","im_detect: 4000/4952 0.055s\n","im_detect: 4500/4952 0.056s\n","im_detect: 4952/4952 0.060s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.3288\n","AP for bicycle = 0.2829\n","AP for bird = 0.0752\n","AP for boat = 0.1741\n","AP for bottle = 0.0672\n","AP for bus = 0.2952\n","AP for car = 0.4808\n","AP for cat = 0.2540\n","AP for chair = 0.1863\n","AP for cow = 0.2097\n","AP for diningtable = 0.0919\n","AP for dog = 0.2512\n","AP for horse = 0.2538\n","AP for motorbike = 0.3290\n","AP for person = 0.4492\n","AP for pottedplant = 0.1085\n","AP for sheep = 0.2595\n","AP for sofa = 0.1674\n","AP for train = 0.3127\n","AP for tvmonitor = 0.3673\n","Mean AP = 0.2472\n","Mean AP:  0.24723162648523758\n","Saving state, epoch: 5\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolov5_m \\\n","                  -bs 16 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFTi_h3879KW","executionInfo":{"status":"ok","timestamp":1704158785441,"user_tz":-540,"elapsed":1279952,"user":{"displayName":"Richard Minsoo Go","userId":"09628967547080180869"}},"outputId":"7fa7d5b5-cb66-4fb1-e2a7-22a662ba4d2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting Arguments.. :  Namespace(seed=42, cuda=True, img_size=640, eval_first=False, tfboard=False, save_folder='weights/', vis_tgt=False, vis_aux_loss=False, fp16=True, batch_size=8, max_epoch=5, wp_epoch=1, eval_epoch=5, no_aug_epoch=20, model='yolov5_l', conf_thresh=0.005, nms_thresh=0.6, topk=1000, pretrained=None, resume=None, nms_class_agnostic=False, data_path='/content/dataset', dataset='voc', load_cache=False, num_workers=4, multi_scale=True, ema=True, min_box_size=8.0, mosaic=None, mixup=None, grad_accumulate=1, distributed=False, dist_url='env://', world_size=1, sybn=False, debug=False)\n","----------------------------------------------------------\n","LOCAL RANK:  -1\n","LOCAL_PROCESS_RANL:  -1\n","WORLD SIZE: 1\n","use cuda\n","==============================\n","Dataset Config: {'data_name': 'VOCdevkit', 'num_classes': 20, 'class_indexs': None, 'class_names': ('aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')} \n","\n","==============================\n","Model: YOLOV5_L ...\n","==============================\n","Transform: yolov5_large-Style ...\n","Transform Config: {'aug_type': 'yolov5', 'degrees': 0.0, 'translate': 0.2, 'scale': [0.1, 2.0], 'shear': 0.0, 'perspective': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'use_ablu': True, 'mosaic_prob': 1.0, 'mixup_prob': 0.15, 'mosaic_type': 'yolov5_mosaic', 'mixup_type': 'yolov5_mixup', 'mixup_scale': [0.5, 1.5]} \n","\n","==============================\n","Build YOLOV5_L ...\n","==============================\n","Model Configuration: \n"," {'backbone': 'cspdarknet', 'bk_act': 'silu', 'bk_norm': 'BN', 'bk_dpw': False, 'width': 1.0, 'depth': 1.0, 'stride': [8, 16, 32], 'max_stride': 32, 'fpn': 'yolov5_pafpn', 'fpn_reduce_layer': 'Conv', 'fpn_downsample_layer': 'Conv', 'fpn_core_block': 'CSPBlock', 'fpn_act': 'silu', 'fpn_norm': 'BN', 'fpn_depthwise': False, 'head': 'decoupled_head', 'head_act': 'silu', 'head_norm': 'BN', 'num_cls_head': 2, 'num_reg_head': 2, 'head_depthwise': False, 'anchor_size': [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45], [59, 119], [116, 90], [156, 198], [373, 326]], 'multi_scale': [0.5, 1.25], 'trans_type': 'yolov5_large', 'anchor_thresh': 4.0, 'loss_obj_weight': 1.0, 'loss_cls_weight': 1.0, 'loss_box_weight': 5.0, 'trainer_type': 'rtcdet'}\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","Head: Decoupled Head\n","==============================\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","GFLOPs : 101.44\n","Params : 36.40 M\n","==============================\n","use Mosaic Augmentation: 1.0\n","use Mixup Augmentation: 0.15\n","==============================\n","==============================\n","use Mosaic Augmentation: 0.0\n","use Mixup Augmentation: 0.0\n","==============================\n","==============================\n","Optimizer: adamw\n","--base lr: 0.000125\n","--momentum: None\n","--weight_decay: 0.05\n","==============================\n","Lr Scheduler: linear\n","Build ModelEMA ...\n","============== Second stage of Training ==============\n"," - Close < Mosaic Augmentation > ...\n"," - Close < Mixup Augmentation > ...\n"," - Rebuild transforms ...\n","Saving state of the last Mosaic epoch-1.\n","============== Third stage of Training ==============\n"," - Close < translate of affine > ...\n"," - Close < scale of affine >...\n"," - Rebuild transforms ...\n","Saving state of the last weak augment epoch-1.\n","Train 1:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 1/5][Iter: 2067/2068][lr: 0.000125][loss_obj: 4.74][loss_cls: 1.73][loss_box: 0.47][losses: 8.83][grad_norm: 10.16][time: 772.01][size: 640]\n","Train 2:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 2/5][Iter: 2067/2068][lr: 0.000133][loss_obj: 4.66][loss_cls: 1.97][loss_box: 0.45][losses: 8.88][grad_norm: 11.09][time: 761.53][size: 352]\n","Train 3:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 3/5][Iter: 2067/2068][lr: 0.000133][loss_obj: 4.45][loss_cls: 1.40][loss_box: 0.47][losses: 8.22][grad_norm: 13.35][time: 768.83][size: 672]\n","Train 4:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 4/5][Iter: 2067/2068][lr: 0.000133][loss_obj: 3.51][loss_cls: 1.77][loss_box: 0.36][losses: 7.08][grad_norm: 11.35][time: 774.42][size: 448]\n","Train 5:   0%|          | 0/2068 [00:00<?, ?it/s]\n","[Epoch: 5/5][Iter: 2067/2068][lr: 0.000133][loss_obj: 3.66][loss_cls: 1.84][loss_box: 0.27][losses: 6.87][grad_norm: 16.14][time: 764.23][size: 800]\n","eval ...\n","im_detect: 500/4952 0.061s\n","im_detect: 1000/4952 0.055s\n","im_detect: 1500/4952 0.055s\n","im_detect: 2000/4952 0.059s\n","im_detect: 2500/4952 0.067s\n","im_detect: 3000/4952 0.063s\n","im_detect: 3500/4952 0.066s\n","im_detect: 4000/4952 0.063s\n","im_detect: 4500/4952 0.066s\n","im_detect: 4952/4952 0.063s\n","Evaluating detections\n","VOC07 metric? Yes\n","AP for aeroplane = 0.3883\n","AP for bicycle = 0.3453\n","AP for bird = 0.1752\n","AP for boat = 0.1947\n","AP for bottle = 0.0431\n","AP for bus = 0.3459\n","AP for car = 0.5482\n","AP for cat = 0.2784\n","AP for chair = 0.1958\n","AP for cow = 0.3470\n","AP for diningtable = 0.1963\n","AP for dog = 0.2759\n","AP for horse = 0.2600\n","AP for motorbike = 0.3375\n","AP for person = 0.5126\n","AP for pottedplant = 0.1060\n","AP for sheep = 0.2096\n","AP for sofa = 0.2549\n","AP for train = 0.3260\n","AP for tvmonitor = 0.3535\n","Mean AP = 0.2847\n","Mean AP:  0.2847093004784919\n","Saving state, epoch: 5\n"]}],"source":["! python train.py --cuda \\\n","                  -d voc \\\n","                  --data_path /content/dataset \\\n","                  -m yolov5_l \\\n","                  -bs 8 \\\n","                  --max_epoch 5 \\\n","                  --wp_epoch 1 \\\n","                  --eval_epoch 5 \\\n","                  --fp16 \\\n","                  --ema \\\n","                  --multi_scale"]},{"cell_type":"code","source":["# Cannot test at Colab-Pro + environment\n","# ! python -m torch.distributed.run --nproc_per_node=8 train.py \\\n","#                                   --cuda \\\n","#                                   -dist \\\n","#                                   -d voc \\\n","#                                   --data_path /content/dataset \\\n","#                                   -m yolov5_s \\\n","#                                   -bs 128 \\\n","#                                   -size 640 \\\n","#                                   --wp_epoch 3 \\\n","#                                   --max_epoch 300 \\\n","#                                   --eval_epoch 10 \\\n","#                                   --no_aug_epoch 20 \\\n","#                                   --ema \\\n","#                                   --fp16 \\\n","#                                   --sybn \\\n","#                                   --multi_scale \\\n","#                                   --save_folder weights/\n"],"metadata":{"id":"KS2VWvIbAj6H"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPiYheZz7DTOa4eU4v0LhLs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}